{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the simplest neural network consisting just of one neuron!\n",
    "# It will predict a mean value of eight numbers.\n",
    "# For example if there is [5, 3, 2, 6] in the input\n",
    "# It will output (5 + 3 + 2 + 6) / 4 = 4.0\n",
    "\n",
    "# Make all imports.\n",
    "# You need to install pandas, numpy, matplotlib and pytorch.\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of all data.\n",
    "data_len = 1024 * 16\n",
    "\n",
    "# Length of the training data: 1024 * 16 - 1024 = 15360 rows.\n",
    "# Remaining 1024 rows are for testing accuracy.\n",
    "data_split = data_len - 1024\n",
    "\n",
    "# Create a dictionary with random numbers (standart normal distribution).\n",
    "# It has eight columns from 'x0' to 'x7'. It's our features.\n",
    "# Each row is called a sample. There are `data_len` samples in the dataset.\n",
    "#\n",
    "# Read about dictionary comprehentions and f-strings in Python\n",
    "# if you don't understand this line.\n",
    "d = {f'x{i}': np.random.randn(data_len) for i in range(4)}\n",
    "\n",
    "# Create a Pandas dataframe from the dictionary.\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "# Make 'y' column with mean values along columns (that's because axis=1).\n",
    "df['y'] = df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x0        x1        x2        x3         y\n",
      "0 -0.372170 -1.217678 -1.274363 -0.187191 -0.762851\n",
      "1 -0.189180  0.730292 -0.078773 -0.502313 -0.009994\n",
      "2 -2.208660  1.066618 -1.023454  0.976092 -0.297351\n",
      "3 -0.790448 -1.836837  2.279384 -1.823200 -0.542776\n",
      "4 -1.058742 -1.661404 -1.234470 -0.117421 -1.018009\n"
     ]
    }
   ],
   "source": [
    "# Show first several samples.\n",
    "print(df.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "-0.7628506576331334\n"
     ]
    }
   ],
   "source": [
    "# You can test that 'y' column is a really a mean value of eight features in each row.\n",
    "sum = 0\n",
    "for i in range(4):\n",
    "    # iloc(0) means than we are extracting the first row.\n",
    "    x = df[f'x{i}'].iloc[0]\n",
    "    sum += x\n",
    "print('-' * 20)\n",
    "\n",
    "# Check if this is equal to 'y' value in the first row.\n",
    "print(sum / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a `MeanDataset` class inherited from `Dataset` class.\n",
    "# This is an abstract class representing a Dataset in pytorch.\n",
    "# All custom datasets should inherit Dataset and override the following methods:\n",
    "# __len__ so that len(dataset) returns the size of the dataset;\n",
    "# __getitem__ to support the indexing such that dataset[i] can be used to get ith sample.\n",
    "\n",
    "class MeanDataset(Dataset):\n",
    "    '''\n",
    "    Mean value dataset.\n",
    "    '''\n",
    "    def __init__(self, df, data_split, test):\n",
    "        '''\n",
    "        df - dataframe;\n",
    "        data_split - how much rows in the training data (remaining are in the testing dataset);\n",
    "        test = {True, False} - test or train dataset.\n",
    "        '''\n",
    "        self.df = df\n",
    "        self.test = test\n",
    "        self.data_split = data_split\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        Returns a sample with specified index which can be in the following in ranges:\n",
    "        0 ... (data_split-1) - for training dataset;\n",
    "        0 ... (len(df)-data_split) - for testing dataset.\n",
    "        '''\n",
    "        if self.test:\n",
    "            # Add `data_split` to the index if this is a testing dataset.\n",
    "            index += self.data_split\n",
    "        elif index > self.data_split-1:\n",
    "            # If this is a training dataset and this is the end of training\n",
    "            # data then exit from for loop.\n",
    "            raise StopIteration\n",
    "            \n",
    "        # Assign `index` row and all columns except the last to `X` variable.\n",
    "        # as_matrix() converts pandas Series to numpy array\n",
    "        X = self.df.iloc[index, :-1].as_matrix()\n",
    "        \n",
    "        # Get the last value from `index` column\n",
    "        y = self.df.iloc[index, -1]\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.test:\n",
    "            return len(self.df) - self.data_split\n",
    "        else:\n",
    "            return self.data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MeanDataset instances with training and testing data separately.\n",
    "train_dataset = MeanDataset(df, data_split, test=False)\n",
    "test_dataset = MeanDataset(df, data_split, test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check dataset objects (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15360\n",
      "15360\n"
     ]
    }
   ],
   "source": [
    "# Length of our train dataset must be equal to the `data_split`\n",
    "count = 0\n",
    "for i in train_dataset:\n",
    "    count += 1\n",
    "print(count)\n",
    "print(data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "# Length of the test dataset must be equal to the (data_len-data_split)\n",
    "count = 0\n",
    "for i in test_dataset:\n",
    "    count += 1\n",
    "print(count)\n",
    "print(data_len-data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Each sample contains two elements: features array and a result.\n",
    "print(len(train_dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(data, index, n):\n",
    "    '''\n",
    "    Auxiliary function: just displays `n` samples from the dataset object starting from `index`.\n",
    "    \n",
    "    Input:\n",
    "    data - MeanDataset object;\n",
    "    index - starting point for displaying;\n",
    "    n - how much samples to display.\n",
    "    '''\n",
    "    columns = [f\"x{i}\" for i in range(4)]\n",
    "    columns.append(\"y\")\n",
    "    index = [i for i in range(index, index+n)]\n",
    "    result = pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "    for i in index:\n",
    "        for j in range(4):\n",
    "            result.loc[i][j] = data[i][0][j]\n",
    "        result.loc[i][-1] = data[i][1]\n",
    "\n",
    "    print(result.to_string(float_format=lambda x: f\"{x:.6f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x0        x1        x2        x3         y\n",
      "0 -0.372170 -1.217678 -1.274363 -0.187191 -0.762851\n",
      "1 -0.189180  0.730292 -0.078773 -0.502313 -0.009994\n",
      "2 -2.208660  1.066618 -1.023454  0.976092 -0.297351\n",
      "3 -0.790448 -1.836837  2.279384 -1.823200 -0.542776\n",
      "4 -1.058742 -1.661404 -1.234470 -0.117421 -1.018009\n"
     ]
    }
   ],
   "source": [
    "# Show first 5 samples from `train` object.\n",
    "show_samples(train_dataset, 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x0        x1        x2        x3         y\n",
      "0 -0.372170 -1.217678 -1.274363 -0.187191 -0.762851\n",
      "1 -0.189180  0.730292 -0.078773 -0.502313 -0.009994\n",
      "2 -2.208660  1.066618 -1.023454  0.976092 -0.297351\n",
      "3 -0.790448 -1.836837  2.279384 -1.823200 -0.542776\n",
      "4 -1.058742 -1.661404 -1.234470 -0.117421 -1.018009\n"
     ]
    }
   ],
   "source": [
    "# Show first 5 samples from the original dataframe. They must be equal.\n",
    "print(df.head(5).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Original dataframe-------------------\n",
      "             x0        x1        x2        x3         y\n",
      "15357 -0.729790 -0.048423 -1.513434  1.022374 -0.317318\n",
      "15358 -0.393401  0.664073 -0.742509 -1.810689 -0.570631\n",
      "15359 -0.838864  0.533188 -2.193586  0.289318 -0.552486\n",
      "15360 -1.168087  2.449318  1.086021 -0.675482  0.422943\n",
      "15361 -0.112024 -1.075465 -3.167638  0.687802 -0.916831\n",
      "15362  0.364389  0.884602 -0.970820  0.465550  0.185930\n",
      "\n",
      "------------Last samples from train dataset------------\n",
      "             x0        x1        x2        x3         y\n",
      "15357 -0.729790 -0.048423 -1.513434  1.022374 -0.317318\n",
      "15358 -0.393401  0.664073 -0.742509 -1.810689 -0.570631\n",
      "15359 -0.838864  0.533188 -2.193586  0.289318 -0.552486\n",
      "\n",
      "------------First samples from test dataset------------\n",
      "         x0        x1        x2        x3         y\n",
      "0 -1.168087  2.449318  1.086021 -0.675482  0.422943\n",
      "1 -0.112024 -1.075465 -3.167638  0.687802 -0.916831\n",
      "2  0.364389  0.884602 -0.970820  0.465550  0.185930\n"
     ]
    }
   ],
   "source": [
    "# Show 6 samples around data_split point and compare it to the last 3 samples from train dataset\n",
    "# and 3 first samples from test dataset.\n",
    "# Notice that indexes in test dataset starting from zero.\n",
    "print('-' * 18 + 'Original dataframe' + '-' * 19)\n",
    "print(df.iloc[data_split-3:].head(6).to_string())\n",
    "print()\n",
    "print('-' * 12 + 'Last samples from train dataset' + '-' * 12)\n",
    "show_samples(train_dataset, data_split-3, 3)\n",
    "print()\n",
    "print('-' * 12 + 'First samples from test dataset' + '-' * 12)\n",
    "show_samples(test_dataset, 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             x0        x1        x2        x3         y\n",
      "16379  1.125337  0.855660  0.726153 -1.119461  0.396922\n",
      "16380 -0.610176  0.498182 -0.934309  0.286530 -0.189943\n",
      "16381  0.590183  0.542074  0.486010 -1.133434  0.121208\n",
      "16382 -1.375578  0.650248 -1.541667 -1.166834 -0.858458\n",
      "16383  0.023187 -0.597918 -0.644188 -0.716463 -0.483845\n"
     ]
    }
   ],
   "source": [
    "# Show the last 5 samples.\n",
    "print(df.tail(5).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            x0        x1        x2        x3         y\n",
      "1019  1.125337  0.855660  0.726153 -1.119461  0.396922\n",
      "1020 -0.610176  0.498182 -0.934309  0.286530 -0.189943\n",
      "1021  0.590183  0.542074  0.486010 -1.133434  0.121208\n",
      "1022 -1.375578  0.650248 -1.541667 -1.166834 -0.858458\n",
      "1023  0.023187 -0.597918 -0.644188 -0.716463 -0.483845\n"
     ]
    }
   ],
   "source": [
    "# And compare it to the last 5 samples from test dataset.\n",
    "show_samples(test_dataset, data_len-data_split-5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader is an iterator which is used for loading data in batches.\n",
    "# You can feed the neural network only one sample at time but this is not very wise because:\n",
    "# 1. Gradients from each sample are more stohastic (we will show this later);\n",
    "# 2. GPU good at parallel tasks and can process many samples simultaneously.\n",
    "# Slicing dataset by batches will use GPU more efficiently (although we don't use GPU\n",
    "# here, but you will definetely use it for larger datasets).\n",
    "#\n",
    "# Why not to pass all data at once? You can do it, but you will get error from GPU\n",
    "# if it has no enough memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=512)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing dataloaders (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30.0\n",
      "---\n",
      "2 x 512\n"
     ]
    }
   ],
   "source": [
    "# We will count number of batches in the train_dataset.\n",
    "count = 0\n",
    "for i in train_loader:\n",
    "    count += 1\n",
    "\n",
    "# This numbers must be equal.\n",
    "print(count)\n",
    "print(len(train_dataset) / 512)\n",
    "print('---')\n",
    "\n",
    "# Dataloader return 2 lists (features X and output y),\n",
    "# each containing 512 samples.\n",
    "print(f\"{len(i)} x {len(i[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0\n",
      "---\n",
      "2 x 512\n"
     ]
    }
   ],
   "source": [
    "# Quickly check test_loader also:\n",
    "count = 0\n",
    "for i in test_loader:\n",
    "    count += 1\n",
    "\n",
    "print(count)\n",
    "print(len(test_dataset) / 512)\n",
    "print('---')\n",
    "print(f\"{len(i)} x {len(i[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Module is a basic class for all neural networks.\n",
    "# You must subclass this class.\n",
    "# At least you must override `forward` method which is called\n",
    "# at each call. It performs one forward propogation throught\n",
    "# the network.\n",
    "\n",
    "class SimplestNN(nn.Module):\n",
    "    '''\n",
    "    One-neuron neural network.\n",
    "    '''\n",
    "    def __init__(self, in_features=4, out_features=1):\n",
    "        '''\n",
    "        in_features - input dimensions (4 features).\n",
    "        out_features - output dimensions (one output).\n",
    "        '''\n",
    "        super().__init__()\n",
    "        # Create linear layer. It's just performs vector multiplication\n",
    "        # of the inputs and weights.\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        y_pred = self.linear(inp)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimplestNN(\n",
      "  (linear): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimplestNN()\n",
    "\n",
    "# As you can see, the model have 4 inputs and one output.\n",
    "# It's also includes the bias.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze neural network (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      " 0.2601 -0.2865 -0.3699  0.0884\n",
      "[torch.FloatTensor of size 1x4]\n",
      "\n",
      "Parameter containing:\n",
      " 0.3372\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show linear layer weights and a bias.\n",
    "# They are randomly initialized.\n",
    "print(model.linear.weight)\n",
    "print(model.linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: -0.7316495180130005\n",
      "Actual: 2.5\n"
     ]
    }
   ],
   "source": [
    "# Use network to predict the mean of 4 numbers.\n",
    "y_pred = model(Variable(torch.FloatTensor([1, 2, 3, 4])))\n",
    "y_actual = (1 + 2 + 3 + 4) / 4\n",
    "# As you can see it performs very poorly because doesn't know what\n",
    "# to do with this four numbers.\n",
    "print(f\"Prediction: {float(y_pred)}\")\n",
    "print(f\"Actual: {y_actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: -0.7316495180130005\n",
      "Prediction: -0.7316495180130005\n"
     ]
    }
   ],
   "source": [
    "# How this prediction has been made? That's simple.\n",
    "\n",
    "# Transpose wights.\n",
    "w = torch.t(model.linear.weight)\n",
    "# This is bias.\n",
    "b = model.linear.bias\n",
    "# This is inputs.\n",
    "X = Variable(torch.FloatTensor([1, 2, 3, 4]))\n",
    "\n",
    "y_pred = w[0] * X[0] + w[1] * X[1] + w[2] * X[2] + w[3] * X[3] + b\n",
    "print(f\"Prediction: {float(y_pred)}\")\n",
    "\n",
    "# Or more compactly:\n",
    "y_pred = torch.dot(w, X) + b\n",
    "print(f\"Prediction: {float(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating optimizer with Adam algorithm with learning rate 1e-2.\n",
    "# It will calculate gradient based on model.parameters().\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-2)\n",
    "\n",
    "# As loss function we will use the mean squared error.\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The several cells below just for explanation of what is going on.\n",
    "# You can skip right to the for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6940860463436538\n",
      "0.6940858960151672\n"
     ]
    }
   ],
   "source": [
    "# Get first batch from train_loader\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "# Get predictions.\n",
    "y_pred = model(Variable(batch[0].float()))\n",
    "\n",
    "# Get the real values.\n",
    "y = batch[1].float()\n",
    "\n",
    "# model() returns Variable object which contains history about\n",
    "# operations on this Varibale. We are not interested in it\n",
    "# so we get only `data` property. view(512) makes one-dimensional\n",
    "# tensor from two-dimensional.\n",
    "loss = torch.sum((y_pred.data.view(512) - y)**2)/512\n",
    "print(f\"{float(loss)}\")\n",
    "\n",
    "# It's equal to previous calculation. Our loss function is just\n",
    "# a sum of squared difference between predicted and actual values\n",
    "# divided by number of samples in the batch.\n",
    "loss = criterion(y_pred, Variable(y))\n",
    "print(f\"{float(loss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradient of the loss function and make one step in the direction\n",
    "# where loss is decreasing the most.\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666650176048279\n"
     ]
    }
   ],
   "source": [
    "# Loss have been got lower.\n",
    "y_pred = model(Variable(batch[0].float()))\n",
    "loss = criterion(y_pred, Variable(y))\n",
    "print(f\"{float(loss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----0 epoch-----\n",
      "0.6666650176048279\n",
      "0.6775162220001221\n",
      "0.667523205280304\n",
      "0.7440598607063293\n",
      "0.6509069800376892\n",
      "0.6184183359146118\n",
      "0.6012232899665833\n",
      "0.6109827160835266\n",
      "0.5884798169136047\n",
      "0.5065759420394897\n",
      "0.5219050645828247\n",
      "0.5143373608589172\n",
      "0.42852547764778137\n",
      "0.37453868985176086\n",
      "0.4224548935890198\n",
      "0.38718080520629883\n",
      "0.34943997859954834\n",
      "0.35851937532424927\n",
      "0.3115392029285431\n",
      "0.313249409198761\n",
      "0.314829558134079\n",
      "0.2815018594264984\n",
      "0.24275627732276917\n",
      "0.26506757736206055\n",
      "0.2513918876647949\n",
      "0.21543729305267334\n",
      "0.22695203125476837\n",
      "0.19017481803894043\n",
      "0.18936774134635925\n",
      "0.2031327486038208\n",
      "-----1 epoch-----\n",
      "0.15000402927398682\n",
      "0.14392782747745514\n",
      "0.13950906693935394\n",
      "0.1527668982744217\n",
      "0.1278299242258072\n",
      "0.12499474734067917\n",
      "0.12116208672523499\n",
      "0.11674601584672928\n",
      "0.11002453416585922\n",
      "0.09352713823318481\n",
      "0.09382862597703934\n",
      "0.09117377549409866\n",
      "0.07610521465539932\n",
      "0.06466460973024368\n",
      "0.07039481401443481\n",
      "0.06305839866399765\n",
      "0.0533873587846756\n",
      "0.056814491748809814\n",
      "0.047644611448049545\n",
      "0.04769545793533325\n",
      "0.04595001041889191\n",
      "0.040362488478422165\n",
      "0.03585594892501831\n",
      "0.035452742129564285\n",
      "0.034850992262363434\n",
      "0.027683336287736893\n",
      "0.029482804238796234\n",
      "0.02316540665924549\n",
      "0.02362377755343914\n",
      "0.024258704856038094\n",
      "-----2 epoch-----\n",
      "0.017396587878465652\n",
      "0.01597587577998638\n",
      "0.015557210892438889\n",
      "0.01598328724503517\n",
      "0.0130708497017622\n",
      "0.0129319466650486\n",
      "0.012153664603829384\n",
      "0.010919088497757912\n",
      "0.009918047115206718\n",
      "0.008328312076628208\n",
      "0.008003358729183674\n",
      "0.00764231663197279\n",
      "0.006147721316665411\n",
      "0.005215371958911419\n",
      "0.005176436621695757\n",
      "0.004690869245678186\n",
      "0.0037180818617343903\n",
      "0.003696745727211237\n",
      "0.003107155207544565\n",
      "0.003040268551558256\n",
      "0.002643531421199441\n",
      "0.00239380169659853\n",
      "0.0020279577001929283\n",
      "0.0018892710795626044\n",
      "0.0017997483955696225\n",
      "0.0013781576417386532\n",
      "0.0013797463616356254\n",
      "0.0010621449910104275\n",
      "0.0010527340928092599\n",
      "0.0009692890453152359\n"
     ]
    }
   ],
   "source": [
    "# You can now repeat this actions again and again\n",
    "# for every batch in train dataset.\n",
    "# This is called a stochastic gradient descent.\n",
    "# The complete passing of the train dataset is called\n",
    "# the epoch. We are doing 3 epoch.\n",
    "for epoch in range(3):\n",
    "    print('-' * 5 + f\"{epoch} epoch\" + '-' * 5)\n",
    "    for batch in train_loader:\n",
    "        y_pred = model(Variable(batch[0].float()))\n",
    "        loss = criterion(y_pred, Variable(batch[1].float()))\n",
    "        print(loss.data[0])\n",
    "        # We must clear gradient because pytorch by default add them\n",
    "        # for each loop cycle.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       " 0.2497  0.2461  0.2228  0.2493\n",
       "[torch.FloatTensor of size 1x4]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights are now near 0.25. That's makes sence because\n",
    "# the mean of four numbers is a sum of each multiplied by 0.25.\n",
    "model.linear.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007288581400644034\n"
     ]
    }
   ],
   "source": [
    "losses = [] # List of loss values for each batch in the test dataset.\n",
    "for batch in test_loader:\n",
    "    y_pred = model(Variable(batch[0].float()))\n",
    "    losses.append(criterion(y_pred, Variable(batch[1].float())).data[0])\n",
    "print(np.mean(losses)) # Compute the mean value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction for arbitrary input (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 2.4077\n",
      "[torch.FloatTensor of size 1x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model(Variable(torch.FloatTensor([[1, 2, 3, 4]])))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 2.4076766967773438\n",
      "Actual: 2.5\n"
     ]
    }
   ],
   "source": [
    "y_actual = (1 + 2 + 3 + 4) / 4\n",
    "# Now the results are better.\n",
    "print(f\"Prediction: {float(y_pred)}\")\n",
    "print(f\"Actual: {y_actual}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
